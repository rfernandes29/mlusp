{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfernandes29/mlusp/blob/main/aula08_nn_e_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9vePrvJasB-"
      },
      "source": [
        "# Redes Neurais\n",
        "\n",
        "Redes neurais são formadas por nós organizados em camadas. Em uma rede neural **densa**, todos os nós de uma dada camada estão conectados a todos os nós das camadas anterior e posterior:\n",
        "\n",
        "![User:Wiso, Public domain, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/9/99/Neural_network_example.svg)\n",
        "*<center>crédito: User:Wiso, Public domain, via Wikimedia Commons</center>*\n",
        "\n",
        "A <font color='green'>primeira camada</font> é composta pelo vetor de entrada $X$, que também podemos chamar de *feature vector*. A <font color='purple'>última camada</font> é composta pelo vetor de saída $y$. As <font color='blue'>camadas intermediárias</font> são chamadas de camadas ocultas. Uma rede neural com mais de uma camada oculta é chamada de rede neural **profunda**. Daí vem o tão conhecido termo *deep learning*.\n",
        "\n",
        "Cada nó faz uma combinação linear de todas as entradas que recebe e depois aplica uma transformação não-linear $\\sigma$ a esta combinação:\n",
        "\n",
        "$z_{nó} = \\sigma(w_1 \\cdot x_1 + w_2 \\cdot x_2 + ... w_n \\cdot x_n + b)$\n",
        "\n",
        "Em notação vetorial, para uma dada camada, seu vetor de saída $Z$ é:\n",
        "\n",
        "$Z = \\sigma(W \\cdot X + B)$\n",
        "\n",
        "As matrizes de pesos $W$ são os parâmetros que queremos otimizar. A transformação não-linear $\\sigma$ é chamada de **função de ativação**.\n",
        "\n",
        "Podemos usar `keras`, uma biblioteca de alto nível, para construir uma rede como a do desenho acima. Chamando o método `.summary()` no modelo, podemos ver a quantidade de parâmetros dele."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb4LQmg6asCQ",
        "outputId": "a62f2bb8-3672-424b-c321-48993cee53cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142 (568.00 Byte)\n",
            "Trainable params: 142 (568.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "x = Input(shape=(4,))\n",
        "\n",
        "z = Dense(6, activation='relu')(x)\n",
        "z = Dense(6, activation='relu')(z)\n",
        "\n",
        "y = Dense(10, activation='softmax')(z)\n",
        "\n",
        "model = Model(inputs=x, outputs=y)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCrmKjHRasDM"
      },
      "source": [
        "### Classificando dígitos do MNIST com redes neurais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aL_qU4hTasDU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D\n",
        "\n",
        "def compile_train(model, X_train, y_train):\n",
        "    model.compile(\n",
        "        optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        verbose=1,\n",
        "        epochs=5,\n",
        "        batch_size=32,\n",
        "        validation_split=0.1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJC6gByVasDw",
        "outputId": "7ab936d8-63d9-474e-ba01-c1bae641a6a3",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "dataset shape (60000, 28, 28)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 9s 4ms/step - loss: 0.2908 - accuracy: 0.9149 - val_loss: 0.1261 - val_accuracy: 0.9628\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1273 - accuracy: 0.9619 - val_loss: 0.0993 - val_accuracy: 0.9705\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9711 - val_loss: 0.0910 - val_accuracy: 0.9757\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0721 - accuracy: 0.9777 - val_loss: 0.0769 - val_accuracy: 0.9768\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 0.0921 - val_accuracy: 0.9710\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "print('dataset shape', X_train.shape)\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "X_train = X_train.reshape((-1, 784))\n",
        "X_test = X_test.reshape((-1, 784))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "compile_train(model, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKdG4_v4asEF"
      },
      "source": [
        "### Classificando peças de roupa com o Fashion MNIST\n",
        "\n",
        "Esta é uma variante um pouco mais desafiadora do MNIST: é um dataset composto por 10 tipos de peça de roupa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlH_FokqasEL",
        "outputId": "13db5e64-bccf-4fd1-d037-c12550904eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118282 (462.04 KB)\n",
            "Trainable params: 118282 (462.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.4964 - accuracy: 0.8232 - val_loss: 0.3949 - val_accuracy: 0.8553\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3701 - accuracy: 0.8654 - val_loss: 0.3616 - val_accuracy: 0.8723\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3337 - accuracy: 0.8774 - val_loss: 0.3927 - val_accuracy: 0.8592\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3126 - accuracy: 0.8843 - val_loss: 0.3545 - val_accuracy: 0.8735\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2929 - accuracy: 0.8911 - val_loss: 0.3366 - val_accuracy: 0.8812\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "X_train = X_train.reshape((-1, 784))\n",
        "X_test = X_test.reshape((-1, 784))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "compile_train(model, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "459KvNQ-asEd"
      },
      "source": [
        "## Redes Neurais Convolucionais\n",
        "\n",
        "\n",
        "Numa rede neural densa, a quantidade de conexões (e, consequentemente, de parâmetros) cresce *exponencialmente* ao adicionarmos mais nós. Assim, para dados de dimensão alta, ou para problemas que exigem modelos muito complexos, é preciso buscar estratégias de conectividade mais eficientes. No caso de imagens, usamos **convoluções**.\n",
        "\n",
        "Numa camada convolucional, também são feitas combinações lineares da camada anterior. A diferença é que agora cada saída é resultado da combinação linear de um subconjunto da entrada, geralmente definido por uma janela quadrada. Isso reduz bastante a quantidade de parâmetros e facilita o reconhecimento de *padrões locais* em imagens.\n",
        "\n",
        "![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides.gif)\n",
        "\n",
        "*<center>crédito: https://github.com/vdumoulin/conv_arithmetic</center>*\n",
        "\n",
        "Vamos construir uma rede neural usando convoluções para tentar melhorar nosso classificador do Fashion MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro4Kt4zBasEk",
        "outputId": "93780c8a-c181-4cff-9114-149395086dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                46090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65194 (254.66 KB)\n",
            "Trainable params: 65194 (254.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 4ms/step - loss: 0.4342 - accuracy: 0.8474 - val_loss: 0.3451 - val_accuracy: 0.8787\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3166 - accuracy: 0.8901 - val_loss: 0.2984 - val_accuracy: 0.8938\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2804 - accuracy: 0.9008 - val_loss: 0.3044 - val_accuracy: 0.8927\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2585 - accuracy: 0.9091 - val_loss: 0.3046 - val_accuracy: 0.8952\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2402 - accuracy: 0.9141 - val_loss: 0.3128 - val_accuracy: 0.8955\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3,3), input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=(3,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "compile_train(model, X_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}